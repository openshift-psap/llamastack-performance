apiVersion: tekton.dev/v1
kind: PipelineRun
metadata:
  generateName: benchmark-responses-simple-
  namespace: tekton-llamastack
spec:
  pipelineRef:
    name: responses-simple-benchmark
  taskRunTemplate:
    serviceAccountName: tekton-deployer
  workspaces:
    - name: results
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 1Gi
  params:
    - name: NAMESPACE
      value: "llamastack-bench"
    - name: DISTRIBUTION_NAME
      value: "llamastack-benchmark"
    - name: MODEL_NAME
      value: "llama-32-3b-instruct"
    - name: USERS
      value: "100"
    - name: RUN_TIME_SECONDS
      value: "60"
    - name: MODEL
      value: "vllm-inference/llama-32-3b-instruct"
    - name: PROMPT
      value: "What is the capital of France?"
    - name: LOAD_SHAPE
      value: "steady"
    - name: ENABLE_MLFLOW
      value: "true"
    - name: MLFLOW_EXPERIMENT
      value: "llamastack-tekton-pipeline"
