apiVersion: llamastack.io/v1alpha1
kind: LlamaStackDistribution
metadata:
  name: llamastack-rhoai32-postgres-otel
  # namespace: will be substituted by run_full_test.sh
spec:
  replicas: 1
  server:
    autoscaling:
      minReplicas: 1
      maxReplicas: 5
      targetCPUUtilizationPercentage: 75
      targetMemoryUtilizationPercentage: 70
    podOverrides:
      serviceAccountName: llamastack-rhoai32-postgres-otel-sa
    containerSpec:
      env:
        - name: VLLM_URL
          value: "http://llama-32-3b-instruct-predictor.avis-project.svc.cluster.local:80/v1"
        - name: INFERENCE_MODEL
          value: "llama-32-3b-instruct"
        - name: VLLM_TLS_VERIFY
          value: "false"
        - name: FMS_ORCHESTRATOR_URL
          value: "http://localhost:1234"
        - name: ENABLE_SENTENCE_TRANSFORMERS
          value: "true"
        - name: EMBEDDING_PROVIDER
          value: "sentence-transformers"
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: "http://otel-collector.avis-project.svc.cluster.local:4318"
        - name: OTEL_SERVICE_NAME
          value: "llamastack"
        - name: OTEL_TRACES_EXPORTER
          value: "otlp"
        - name: POSTGRES_HOST
          value: "postgres.avis-project.svc.cluster.local"
        - name: POSTGRES_PORT
          value: "5432"
        - name: POSTGRES_DB
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: POSTGRES_DB
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: POSTGRES_USER
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: POSTGRES_PASSWORD
      name: llama-stack
      port: 8321
    distribution:
      # Use LlamaStack image with OTEL support
      image: quay.io/aipcc/llama-stack/cpu-ubi9:rhoai-3.2-1765964453
    storage:
      size: 20Gi
      mountPath: /opt/app-root/src/.llama/distributions/rh

