apiVersion: batch/v1
kind: Job
metadata:
  name: guidellm-vllm-concurrency-128
  namespace: bench
spec:
  ttlSecondsAfterFinished: 86400
  backoffLimit: 0
  template:
    metadata:
      labels:
        job-name: guidellm-vllm-concurrency-128
    spec:
      restartPolicy: Never
      #securityContext:
      #  runAsUser: 1000
      #  fsGroup: 1000
      initContainers:
        - name: timestamp-generator
          image: busybox
          command: ["sh", "-c"]
          args:
            - |
              TS=$(date +"%Y%m%d-%H%M%S");
              echo $TS > /shared/timestamp;
              echo "Generated timestamp: $TS"
          volumeMounts:
            - name: shared-data
              mountPath: /shared
      containers:
        - name: benchmark
          image: quay.io/rh-ee-tosokin/guidellm:0.3.1
          imagePullPolicy: Always
          env:
            - name: GUIDELLM__MAX_WORKER_PROCESSES
              value: "1"
            - name: GUIDELLM__STREAM
              value: "false"
          command: ["/bin/bash", "-c"]
          args:
            - |
              echo "Running vLLM benchmark...";
              export HF_TOKEN=$(cat /secrets/token);
              export TRANSFORMERS_OFFLINE=0;
              export HF_HUB_DISABLE_TELEMETRY=1;
              export HF_HOME=/cache;
              export TRANSFORMERS_CACHE=/cache;
              export HOME=/cache;
              TS=$(cat /shared/timestamp);
              OUTPUT_FILE="/output/results-guidellm-vllm-concurrency-128-${TS}.json";
              guidellm benchmark \
                --output-path $OUTPUT_FILE \
                --target http://llama-32-3b-instruct-predictor.bench.svc.cluster.local/v1 \
                --model llama-32-3b-instruct \
                --processor meta-llama/Llama-3.2-3B-Instruct \
                --rate-type concurrent \
                --rate "128" \
                --max-seconds 300 \
                --data "prompt_tokens=256,output_tokens=128";
              echo "vLLM Benchmark complete. Results stored in $OUTPUT_FILE";
              echo "done" > /shared/benchmark_complete;
              echo "Signaled nvidia-smi monitor to stop"
          volumeMounts:
            - name: results-volume
              mountPath: /output
            - name: hf-secret
              mountPath: /secrets
              readOnly: true
            - name: hf-cache
              mountPath: /cache
            - name: shared-data
              mountPath: /shared
        - name: dcgm-metrics-scraper
          image: curlimages/curl
          command: ["sh", "-c"]
          args:
            - |
              echo "Starting DCGM metric scraping...";
              TS=$(cat /shared/timestamp);
              OUTPUT_FILE="/output/results-dcgm-${TS}.txt";
              while true; do
                if [ -f /shared/benchmark_complete ]; then
                  echo "Benchmark completed signal received. Stopping metrics scrape.";
                  break;
                fi
                curl -s http://nvidia-dcgm-exporter.nvidia-gpu-operator.svc.cluster.local:9400/metrics >> $OUTPUT_FILE
                echo "---" >> $OUTPUT_FILE
                sleep 1
              done;
              echo "Metrics scraping stopped. Data saved to $OUTPUT_FILE";
          volumeMounts:
            - name: results-volume
              mountPath: /output
            - name: shared-data
              mountPath: /shared
        - name: vllm-metrics-scraper
          image: curlimages/curl
          command: ["sh", "-c"]
          args:
            - |
              echo "Starting vLLM metrics scraping...";
              TS=$(cat /shared/timestamp);
              OUTPUT_FILE="/output/results-vllm-${TS}.txt";
              while true; do
                if [ -f /shared/benchmark_complete ]; then
                  echo "Benchmark completed signal received. Stopping vLLM metrics scrape.";
                  break;
                fi
                curl -s http://llama-32-3b-instruct-predictor.bench.svc.cluster.local/metrics >> $OUTPUT_FILE
                echo "---" >> $OUTPUT_FILE
                sleep 1
              done;
              echo "vLLM metrics scraping stopped. Data saved to $OUTPUT_FILE";
          volumeMounts:
            - name: results-volume
              mountPath: /output
            - name: shared-data
              mountPath: /shared
        - name: sidecar
          image: busybox
          command: ["sh", "-c", "sleep infinity"]
          volumeMounts:
            - name: results-volume
              mountPath: /output
      volumes:
        - name: results-volume
          emptyDir: {}
        - name: hf-secret
          secret:
            secretName: hf-token-secret
        - name: hf-cache
          emptyDir: {}
        - name: shared-data
          emptyDir: {} 